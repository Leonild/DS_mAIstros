{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonild/DS_mAIstros/blob/main/Bayesian_Inference_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GitHub\n",
        "\n",
        "The code is available on: https://github.com/Leonild/DS_mAIstros/blob/main/Bayesian_Inference_KNN.ipynb"
      ],
      "metadata": {
        "id": "-hPHUgmMDEnB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6crxGdzqipB_"
      },
      "source": [
        "#Importing data\n",
        "Importing from cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PJ9lnN3ibX6",
        "outputId": "72764199-4b38-46de-b7f4-d02ac63c6ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 787)\n",
            "(10000, 787)\n",
            "(60000, 787)\n",
            "(10000, 787)\n",
            "   Unnamed: 0  index  labels  0  1  2  3  4  5  6  ...  774  775  776  777  \\\n",
            "0           0      0       5  0  0  0  0  0  0  0  ...    0    0    0    0   \n",
            "1           1      1       0  0  0  0  0  0  0  0  ...    0    0    0    0   \n",
            "2           2      2       4  0  0  0  0  0  0  0  ...    0    0    0    0   \n",
            "3           3      3       1  0  0  0  0  0  0  0  ...    0    0    0    0   \n",
            "4           4      4       9  0  0  0  0  0  0  0  ...    0    0    0    0   \n",
            "\n",
            "   778  779  780  781  782  783  \n",
            "0    0    0    0    0    0    0  \n",
            "1    0    0    0    0    0    0  \n",
            "2    0    0    0    0    0    0  \n",
            "3    0    0    0    0    0    0  \n",
            "4    0    0    0    0    0    0  \n",
            "\n",
            "[5 rows x 787 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal as mvn\n",
        "\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/EnhanceIT/Data_training/MNIST_train.csv')\n",
        "\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/EnhanceIT/Data_training/MNIST_test.csv')\n",
        "\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)\n",
        "\n",
        "data_test=data_test.drop_duplicates()\n",
        "data_train=data_train.drop_duplicates()\n",
        "\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)\n",
        "\n",
        "print(data_train.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP9wk0fR9eYn"
      },
      "source": [
        "# Baysian Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y6A8GGu69jha"
      },
      "outputs": [],
      "source": [
        "class GaussBayes():\n",
        "\n",
        "  def fit(self, X, y, epsilon = 1e-3):\n",
        "    self.likelihoods = dict()\n",
        "    self.priors = dict()\n",
        "\n",
        "    self.K = set(y.astype(int))\n",
        "\n",
        "    for k in self.K:\n",
        "      X_k = X[y==k,:]\n",
        "      N_k, D = X_k.shape\n",
        "      mu_k = X_k.mean(axis=0)\n",
        "      #calculating by covariance matrix\n",
        "      self.likelihoods[k] = {\"mean\": X_k.mean(axis=0), \n",
        "                             \"covariance\": (1/(N_k - 1)) * np.matmul((X_k-mu_k).T,(X_k-mu_k))+\n",
        "                             epsilon*np.identity(D)}\n",
        "      self.priors[k] = len(X_k)/len(X)\n",
        "      \n",
        "  def predict(self, X):\n",
        "    N, D = X.shape\n",
        "    #probability verctor/matrix\n",
        "    P_hat = np.zeros((N, len(self.K)))\n",
        "\n",
        "    for k, l in self.likelihoods.items():\n",
        "      P_hat[:,k] = mvn.logpdf(X, l[\"mean\"], l[\"covariance\"]) + np.log(self.priors[k])\n",
        "\n",
        "    return P_hat.argmax(axis=1) #returning the hights probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Z8X06DCQ6T"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SU7joIK9CYMx"
      },
      "outputs": [],
      "source": [
        "#What is the average time that they match\n",
        "def accuracy(y, y_hat):\n",
        "  return np.mean(y==y_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmwyxdR696Ko"
      },
      "source": [
        "## Testing solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwZ8uBi98hq",
        "outputId": "bc35fddb-4407-41be-f4bb-4faeca01d348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7532"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_train = data_train.to_numpy()\n",
        "\n",
        "X_test = data_test.to_numpy()\n",
        "#print(X_test)\n",
        "print(set(X_train[:,2]))\n",
        "\n",
        "y = X_train[:,2] #getting the labels\n",
        "X_train = X_train[:,3:] # 3 cause the first 2 are indexes and the 3sd is the lable\n",
        "\n",
        "y_test = X_test[:,2] #getting the labels\n",
        "X_test = X_test[:,3:] # 3 cause the first 2 are indexes and the 3sd is the lable\n",
        "\n",
        "#print(X_test)\n",
        "\n",
        "MNIST_gnb = GaussBayes()\n",
        "\n",
        "MNIST_gnb.fit(X_train,y)\n",
        "y_hat = MNIST_gnb.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy(y_test, y_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzuCfcYiCrCZ"
      },
      "source": [
        "#KNN Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MXnsGjdRCw7g"
      },
      "outputs": [],
      "source": [
        "class KNNClassifier():\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def predict(self, X, k, epsilon = 1e-3):\n",
        "    N = len(X)\n",
        "    y_hat = np.zeros(N)\n",
        "\n",
        "    for i in range(N):\n",
        "      # getting list of distances\n",
        "      dist2 = np.sum((self.X - X[i]) ** 2, axis=1)\n",
        "      idxt = np.argsort(dist2)[:k] # the k nearest\n",
        "      # a list of the 1/distances\n",
        "      gamma_k = 1 / (np.sqrt(dist2[idxt]+epsilon))\n",
        "      y_hat[i] = np.bincount(self.y[idxt], weights=gamma_k).argmax()\n",
        "    \n",
        "    return y_hat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAW-2YyFC8ti"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3U4POrXVC968"
      },
      "outputs": [],
      "source": [
        "#What is the average time that they match\n",
        "def accuracy(y, y_hat):\n",
        "  return np.mean(y==y_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iBvGU3FDIzG"
      },
      "source": [
        "## Testing Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1w3kXVKDLr-",
        "outputId": "72a81885-e219-4576-f05a-abf24a0925ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        }
      ],
      "source": [
        "X_train = data_train.to_numpy()\n",
        "\n",
        "X_test = data_test.to_numpy()\n",
        "#print(X_test)\n",
        "print(set(X_train[:,2]))\n",
        "\n",
        "y = X_train[:,2] #getting the labels\n",
        "X_train = X_train[:,3:] # 3 cause the first 2 are indexes and the 3sd is the lable\n",
        "\n",
        "y_test = X_test[:,2] #getting the labels\n",
        "X_test = X_test[:,3:] # 3 cause the first 2 are indexes and the 3sd is the lable\n",
        "\n",
        "#print(X_test)\n",
        "\n",
        "#MNIST_knn = KNNClassifier()\n",
        "\n",
        "#MNIST_knn.fit(X_train,y)\n",
        "#y_hat = MNIST_knn.predict(X_test,5)\n",
        "\n",
        "#accuracy(y_test, y_hat) # 0.96 28m 28 s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBY9eQpYS0U6"
      },
      "source": [
        "## Tuning\n",
        "\n",
        "We may need to tune the hyperparameters of KNN because they can significantly affect the performance of the algorithm. In particular, the value of the hyperparameter \"k\" which determines the number of neighbors to consider for classification or regression, can have a significant impact on the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FlfGdX10S34F"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# get the start time\n",
        "st_total = time.time()\n",
        "MNIST_knn = KNNClassifier()\n",
        "MNIST_knn.fit(X_train,y)\n",
        "for i in range(5,20,5):\n",
        "  st = time.time() # get the start time\n",
        "  print(\"Execution for k = \", i)\n",
        "  y_hat = MNIST_knn.predict(X_test,i)\n",
        "  print(\"Accuracy: \", accuracy(y_test, y_hat))\n",
        "  et = time.time() # get the end time\n",
        "  elapsed_time = et - st\n",
        "  print('Execution time:', elapsed_time, 'seconds\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "# get the end time\n",
        "et_total = time.time()\n",
        "\n",
        "# get the execution time\n",
        "elapsed_time = et_total - st_total\n",
        "print('Experiment time:', elapsed_time, 'seconds')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SPFoN_0AUehUv5rYYnYh3GtGOSKTwhIb",
      "authorship_tag": "ABX9TyOVVCwC8/0KGDDxs5W7AjaM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}